{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cb664b",
   "metadata": {},
   "source": [
    "# Demo — CNN + Majority Vote (19-slice OCT volume)\n",
    "\n",
    "This notebook runs **inference only** for the baseline model:\n",
    "- **Per-slice ResNet-50** → softmax probabilities\n",
    "- **Volume-level prediction** = **majority vote** across the 19 slices  \n",
    "  (ties resolved by mean probability)\n",
    "\n",
    "It is designed to work **directly after cloning this GitHub repo**.\n",
    "\n",
    "**What you need to change:** only the variables in the **CONFIG** cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Recommended) install dependencies (run once)\n",
    "# If you already ran `pip install -r requirements.txt` in a terminal, you can skip this cell.\n",
    "\n",
    "!pip -q install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106a26f",
   "metadata": {},
   "source": [
    "## 1) CONFIG (edit only this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Folder that contains your images.\n",
    "# You can point to: train/ or val/ or test/ OR directly to a class folder (CHM/ USH2A/ Healthy/)\n",
    "INPUT_DIR = Path(r\"/path/to/your/data\")  # <-- CHANGE THIS\n",
    "\n",  
    "CLASS_NAMES = [\"CHM\", \"Healthy\", \"USH2A\"] \n",
    "\n",
    "# Checkpoint filename (downloaded from GitHub Releases v1.0 into ./weights/)\n",
    "WEIGHTS_PATH = Path(\"weights/cnn_resnet50_2025-10-20_best.pt\")\n",
    "\n",
    "# Device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"INPUT_DIR :\", INPUT_DIR)\n",
    "print(\"WEIGHTS   :\", WEIGHTS_PATH)\n",
    "print(\"DEVICE    :\", DEVICE)\n",
    "print(\"CLASSES   :\", CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e3b03",
   "metadata": {},
   "source": [
    "## 2) Download checkpoints (from GitHub Releases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16331621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This downloads all *.pt assets from Releases/v1.0 into ./weights/\n",
    "# If you already downloaded them, the script will skip existing files.\n",
    "\n",
    "!python tools/download_checkpoints.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a85ef",
   "metadata": {},
   "source": [
    "## 3) Inference code (baseline CNN + vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea42195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from pathlib import Path\n",
    "\n",
    "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"}\n",
    "\n",
    "def parse_filename(fname: str) -> Optional[Tuple[str, str, int]]:\n",
    "    \"\"\"\n",
    "    Expected filename format:\n",
    "      <id1>_<id2>_<id3>_<eye>_<slice>.<ext>\n",
    "    Example:\n",
    "      371_4646_28891_R_01.PNG\n",
    "\n",
    "    Returns: (patient_id, eye, slice_idx) with slice_idx in [1..19]\n",
    "    \"\"\"\n",
    "    stem = Path(fname).stem  # removes extension\n",
    "    parts = stem.split(\"_\")\n",
    "    if len(parts) < 5:\n",
    "        return None\n",
    "    patient_id = \"_\".join(parts[:3])\n",
    "    eye = parts[3]\n",
    "    m = re.match(r\"^(\\d+)$\", parts[4])\n",
    "    if m is None:\n",
    "        return None\n",
    "    slice_idx = int(m.group(1))\n",
    "    return patient_id, eye, slice_idx\n",
    "\n",
    "def infer_true_label_from_path(p: Path, class_names: List[str]) -> Optional[str]:\n",
    "    parts = [x.lower() for x in p.parts]\n",
    "    for c in class_names:\n",
    "        if c.lower() in parts:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def collect_volumes(input_dir: Path, class_names: List[str]) -> Dict[Tuple[str, str, Optional[str]], Dict[int, Path]]:\n",
    "    vols: Dict[Tuple[str, str, Optional[str]], Dict[int, Path]] = defaultdict(dict)\n",
    "    for p in input_dir.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMG_EXTS:\n",
    "            continue\n",
    "        parsed = parse_filename(p.name)\n",
    "        if parsed is None:\n",
    "            continue\n",
    "        patient_id, eye, slice_idx = parsed\n",
    "        true_label = infer_true_label_from_path(p, class_names)\n",
    "        key = (patient_id, eye, true_label)\n",
    "        vols[key][slice_idx] = p\n",
    "    return vols\n",
    "\n",
    "class CNNResNet50(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper so that state_dict keys match 'resnet.*' (as in your checkpoint).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "def load_model(weights_path: Path, num_classes: int, device: str) -> nn.Module:\n",
    "    model = CNNResNet50(num_classes=num_classes).to(device)\n",
    "    sd = torch.load(weights_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def build_transform(image_size: int = 224):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],  # ImageNet\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_volume(model: nn.Module, slice_paths: List[Path], tfm, device: str):\n",
    "    probs = []\n",
    "    slice_preds = []\n",
    "    for p in slice_paths:\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        x = tfm(img).unsqueeze(0).to(device)\n",
    "        logits = model(x)\n",
    "        prob = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
    "        probs.append(prob)\n",
    "        slice_preds.append(int(prob.argmax()))\n",
    "\n",
    "    probs = np.stack(probs, axis=0)\n",
    "    prob_mean = probs.mean(axis=0)\n",
    "\n",
    "    vote = Counter(slice_preds).most_common()\n",
    "    top_count = vote[0][1]\n",
    "    top_classes = [cls for cls, cnt in vote if cnt == top_count]\n",
    "\n",
    "    if len(top_classes) == 1:\n",
    "        pred_idx = top_classes[0]\n",
    "    else:\n",
    "        pred_idx = int(np.argmax(prob_mean))\n",
    "\n",
    "    return pred_idx, prob_mean, slice_preds\n",
    "\n",
    "def run_cnn_vote(input_dir: Path, weights_path: Path, class_names: List[str], device: str, image_size: int = 224) -> pd.DataFrame:\n",
    "    vols = collect_volumes(input_dir, class_names)\n",
    "    if len(vols) == 0:\n",
    "        raise RuntimeError(\"No images found. Check INPUT_DIR and filename format like 371_4646_28891_R_01.PNG.\")\n",
    "\n",
    "    model = load_model(weights_path, num_classes=len(class_names), device=device)\n",
    "    tfm = build_transform(image_size=image_size)\n",
    "\n",
    "    rows = []\n",
    "    skipped = 0\n",
    "    expected = list(range(1, 20))\n",
    "\n",
    "    for (patient_id, eye, true_label), slice_map in sorted(vols.items()):\n",
    "        if not all(k in slice_map for k in expected):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        slice_paths = [slice_map[i] for i in expected]\n",
    "        pred_idx, prob_mean, slice_preds = predict_volume(model, slice_paths, tfm, device)\n",
    "\n",
    "        row = {\n",
    "            \"patient_id\": patient_id,\n",
    "            \"eye\": eye,\n",
    "            \"true_label\": true_label if true_label is not None else \"\",\n",
    "            \"pred_label\": class_names[pred_idx],\n",
    "            \"pred_idx\": int(pred_idx),\n",
    "            \"device\": device,\n",
    "        }\n",
    "        for j, cname in enumerate(class_names):\n",
    "            row[f\"prob_{cname}\"] = float(prob_mean[j])\n",
    "\n",
    "        counts = Counter(slice_preds)\n",
    "        for j, cname in enumerate(class_names):\n",
    "            row[f\"vote_{cname}\"] = int(counts.get(j, 0))\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if skipped > 0:\n",
    "        print(f\"⚠️ Skipped {skipped} volume(s) because some slices 01..19 were missing.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03fe70",
   "metadata": {},
   "source": [
    "## 4) Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_cnn_vote(\n",
    "    input_dir=INPUT_DIR,\n",
    "    weights_path=WEIGHTS_PATH,\n",
    "    class_names=CLASS_NAMES,\n",
    "    device=DEVICE,\n",
    ")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03d77e",
   "metadata": {},
   "source": [
    "## 5) Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"outputs\").mkdir(parents=True, exist_ok=True)\n",
    "out_path = Path(\"outputs/predictions_cnn_vote.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
